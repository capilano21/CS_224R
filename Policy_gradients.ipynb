{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeBoard:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros(9)\n",
        "        self.current_player = 1\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros(9)\n",
        "        self.current_player = 1\n",
        "\n",
        "    def make_move(self, move):\n",
        "        if self.board[move] != 0:\n",
        "            # Illegal move, game over\n",
        "            print(\"Illegal move has been made\")\n",
        "            self.reset()\n",
        "            return False\n",
        "\n",
        "        self.board[move] = self.current_player\n",
        "        self.current_player = -1 if self.current_player == 1 else 1\n",
        "\n",
        "        return True\n",
        "\n",
        "    def make_mask(self):\n",
        "\n",
        "       mask = self.board==0\n",
        "       return mask\n",
        "\n",
        "    def is_game_over(self):\n",
        "        winning_combinations = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rows\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # columns\n",
        "            [0, 4, 8], [2, 4, 6]              # diagonals\n",
        "        ]\n",
        "\n",
        "        for combination in winning_combinations:\n",
        "            if self.board[combination[0]] == self.board[combination[1]] == self.board[combination[2]] != 0:\n",
        "                return True\n",
        "\n",
        "        return 0 not in self.board\n",
        "\n",
        "    def get_winner(self):\n",
        "        winning_combinations = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rows\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # columns\n",
        "            [0, 4, 8], [2, 4, 6]              # diagonals\n",
        "        ]\n",
        "\n",
        "        for combination in winning_combinations:\n",
        "            if self.board[combination[0]] == self.board[combination[1]] == self.board[combination[2]] != 0:\n",
        "                return self.board[combination[0]]\n",
        "\n",
        "        return 0.5\n",
        "\n",
        "def award_points(result):\n",
        "    if result == 1:\n",
        "        return [1.0,-1.0]\n",
        "    elif result == -1:\n",
        "        return [-1.0,1.0]\n",
        "    else:\n",
        "        return [0.5,0.5]\n",
        "\n",
        "# Example usage:\n",
        "board = TicTacToeBoard()\n",
        "board.make_move(0)  # X plays at position 0\n",
        "board.make_move(4)  # O plays at position 4\n",
        "board.make_move(1)  # X plays at position 1\n",
        "board.make_move(3)  # O plays at position 3\n",
        "board.make_move(5)  # X plays at position 2\n",
        "\n",
        "game_over = board.is_game_over()\n",
        "winner = board.get_winner()\n",
        "\n",
        "if game_over:\n",
        "    points = award_points(winner)\n",
        "    print(f\"Game over! Winner: {winner}, Points: {points}\")\n",
        "else:\n",
        "    print(\"Game not over yet.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddff8284-eea5-4c3c-a2ae-2b0c78e422cf",
        "id": "174LTzvN43oT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Game not over yet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_player(board):\n",
        "  mask = board.make_mask()\n",
        "  choices = np.where(mask==1)[0]\n",
        "  move = np.random.choice(choices)\n",
        "  #board.make_move(move)\n",
        "  return move"
      ],
      "metadata": {
        "id": "jKRdcGTnAlf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "class Player():\n",
        "   def __init__(self,board,style,player):\n",
        "      self.style = style\n",
        "      self.player = player\n",
        "      self.board = board\n",
        "   def make_move(self):\n",
        "       move = self.player(self.board)\n",
        "       return move\n",
        "player_1 = Player(board,style=1.0,player=random_player)\n",
        "player_2 = Player(board,style =-1.0,player= random_player)\n",
        "\n",
        "strategies = [player_1,player_2]\n",
        "strategies = itertools.cycle(strategies)\n",
        "\n",
        "for games in range(100):\n",
        "  board.reset()\n",
        "  count = 0\n",
        "  while True:\n",
        "    count+=1\n",
        "    player = next(strategies)\n",
        "    #print(player.style)\n",
        "    move = player.make_move()\n",
        "    board.make_move(move)\n",
        "    if(board.is_game_over()):\n",
        "      print(\"Game over\")\n",
        "      print(count)\n",
        "      winner = board.get_winner()\n",
        "      if(winner==1):\n",
        "        print(\"X wins\")\n",
        "      elif(winner==0.5):\n",
        "        print(\"Draw\")\n",
        "      else:\n",
        "        print('Lost')\n",
        "      reward = award_points(winner)\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QYw9ur8uEaEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DkCQRGPvK4U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2]\n",
        "b = itertools.cycle(a)\n",
        "for i in range(50):\n",
        "  print(next(b))"
      ],
      "metadata": {
        "id": "nwxZGlh4K461"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        logits = self.fc2(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "    def get_action(self, state, legal_moves, temperature):\n",
        "        logits = self.forward(state)\n",
        "        masked_logits = logits.clone()\n",
        "        masked_logits[~legal_moves] = float('-inf')  # Apply mask to illegal moves\n",
        "\n",
        "        if temperature > 0:\n",
        "            adjusted_logits = masked_logits / temperature  # Adjust logits with temperature\n",
        "        else:\n",
        "            adjusted_logits = masked_logits\n",
        "\n",
        "        action_probs = torch.softmax(adjusted_logits, dim=0)\n",
        "        action = torch.multinomial(action_probs, 1).item()\n",
        "        log_prob = torch.log_softmax(adjusted_logits, dim=0)[action]\n",
        "\n",
        "        return action, log_prob\n"
      ],
      "metadata": {
        "id": "Qh5sXdNfQ1Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "board = TicTacToeBoard()\n",
        "print(board.board)\n",
        "board.make_move(0)\n",
        "print(board.board)\n",
        "board.make_move(1)\n",
        "mask = board.make_mask().astype(float)\n",
        "board = random_player(board)\n",
        "print(board.board)\n",
        "board = random_player(board)\n",
        "print(board.board)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m4qq_6lt_B_",
        "outputId": "f125400c-598b-4a76-bdba-5018d4333a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1. -1.  1.  0.  0.  0.  0.  0.  0.]\n",
            "[ 1. -1.  1.  0. -1.  0.  0.  0.  0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, legal_moves):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Apply the mask to illegal moves\n",
        "        x = x.masked_fill(legal_moves == 0, float('-inf'))\n",
        "\n",
        "        # Apply softmax activation\n",
        "        x = F.softmax(x, dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "input_size = 9  # Size of input state\n",
        "hidden_size = 128  # Size of hidden layer\n",
        "output_size = 9  # Size of output action space\n",
        "\n",
        "# Create an instance of the policy network\n",
        "policy_net = PolicyNetwork(input_size, hidden_size, output_size)\n",
        "\n",
        "# Example input state and legal moves mask\n",
        "state = torch.zeros((1,9))  # Example state (1 x 9)\n",
        "legal_moves = torch.ones((1,9))  # Example legal moves mask (1 x 9)\n",
        "\n",
        "# Forward pass through the policy network\n",
        "probs = policy_net(state, legal_moves)\n",
        "\n",
        "print(\"Action Probabilities:\", probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZI4k-cfXQb1",
        "outputId": "52f283bd-27cf-4ba1-a96a-5992c0567732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Probabilities: tensor([[0.1059, 0.1273, 0.1254, 0.1162, 0.1128, 0.0904, 0.1219, 0.0925, 0.1076]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ]
}